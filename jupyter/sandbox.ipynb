{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import fasttext as ft\n",
    "from keras.layers import Dense, Masking, Conv1D, MaxPooling1D, Embedding, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6362\n",
      "1759\n"
     ]
    }
   ],
   "source": [
    "# Load train and test\n",
    "# train = pd.read_csv('/home/michael/school/research/convote/convote_1train_dev.csv')\n",
    "# test = pd.read_csv('/home/michael/school/research/convote/convote_1test.csv')\n",
    "train = pd.read_csv('/usr2/mamille2/convote/convote_1train_dev.csv')\n",
    "test = pd.read_csv('/usr2/mamille2/convote/convote_1test.csv')\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define classes order\n",
    "class_idx = {'d':[1,0,0], 'i':[0,1,0], 'r':[0,0,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6362, 15030)\n",
      "(1759, 15030)\n",
      "(6362, 3)\n",
      "(1759, 3)\n"
     ]
    }
   ],
   "source": [
    "v_all = TfidfVectorizer(min_df=1)\n",
    "v = TfidfVectorizer(min_df=1, stop_words='english')\n",
    "\n",
    "docs_train = train['text'].values\n",
    "docs_test = test['text'].values\n",
    "y_train = np.array([class_idx[y] for y in train['party'].tolist()])\n",
    "y_test = np.array([class_idx[y] for y in test['party'].tolist()])\n",
    "\n",
    "bow = v.fit(docs_train)\n",
    "bow = v.fit(docs_test)\n",
    "v_all.fit(docs_train)\n",
    "v_all.fit(docs_test)\n",
    "\n",
    "X_train = v.transform(docs_train)\n",
    "X_test = v.transform(docs_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load fasttext word embeddings\n",
    "wembed = ft.load_model('/usr2/mamille2/discourse_connectives/en_wiki_stanford_model_300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vocab\n",
    "vocab = v_all.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15319, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build weights\n",
    "vocab_embed = np.empty((len(vocab),300))\n",
    "\n",
    "for i, wd in enumerate(vocab):\n",
    "    vocab_embed[i,:] = wembed[wd]\n",
    "    \n",
    "vocab_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save vocab pretrained\n",
    "np.save('../../vocab.npy', vocab_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load vocab pretrained\n",
    "vocab_embed = np.load('../../vocab.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize Keras layer with weights\n",
    "def pretrained(shape, dtype=None):\n",
    "    return vocab_embed # shape (vocab, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert texts to sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(docs_train)\n",
    "tokenizer.fit_on_texts(docs_test)\n",
    "\n",
    "seqs_train = tokenizer.texts_to_sequences(docs_train)\n",
    "seqs_test = tokenizer.texts_to_sequences(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pad_sequences(seqs_train, maxlen=1000)\n",
    "X_test = pad_sequences(seqs_test, maxlen=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27767"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "len(word_index) # don't know why this isn't 10k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(word_index) + 1, 300, input_length=1000, embeddings_initializer=pretrained, trainable=False))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5))\n",
    "model.add(Conv1D(128, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5))\n",
    "# model.add(Conv1D(128, kernel_size=5, activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=35)) # large (global?) max pooling\n",
    "model.add(Flatten()) # Not sure why need this\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax')) # final classification layer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6362, 1000)\n",
      "(6362, 3)\n",
      "(1759, 1000)\n",
      "(1759, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6362 samples, validate on 1759 samples\n",
      "Epoch 1/20\n",
      "6362/6362 [==============================] - 439s - loss: 0.7143 - acc: 0.5437 - val_loss: 0.7609 - val_acc: 0.5077\n",
      "Epoch 2/20\n",
      "6362/6362 [==============================] - 483s - loss: 0.7038 - acc: 0.5709 - val_loss: 0.6966 - val_acc: 0.5674\n",
      "Epoch 3/20\n",
      "6362/6362 [==============================] - 478s - loss: 0.6834 - acc: 0.6064 - val_loss: 0.6939 - val_acc: 0.5844\n",
      "Epoch 4/20\n",
      "6362/6362 [==============================] - 486s - loss: 0.6553 - acc: 0.6338 - val_loss: 0.7176 - val_acc: 0.5867\n",
      "Epoch 5/20\n",
      "6362/6362 [==============================] - 486s - loss: 0.6198 - acc: 0.6734 - val_loss: 0.7298 - val_acc: 0.5793\n",
      "Epoch 6/20\n",
      "6362/6362 [==============================] - 500s - loss: 0.5658 - acc: 0.7120 - val_loss: 0.7166 - val_acc: 0.5930\n",
      "Epoch 7/20\n",
      "6362/6362 [==============================] - 513s - loss: 0.5083 - acc: 0.7502 - val_loss: 0.9176 - val_acc: 0.5765\n",
      "Epoch 8/20\n",
      "6362/6362 [==============================] - 523s - loss: 0.4597 - acc: 0.7746 - val_loss: 0.9792 - val_acc: 0.5924\n",
      "Epoch 9/20\n",
      "6362/6362 [==============================] - 501s - loss: 0.4221 - acc: 0.7982 - val_loss: 0.9952 - val_acc: 0.5981\n",
      "Epoch 10/20\n",
      "6362/6362 [==============================] - 501s - loss: 0.3786 - acc: 0.8192 - val_loss: 1.2392 - val_acc: 0.5884\n",
      "Epoch 11/20\n",
      "6362/6362 [==============================] - 509s - loss: 0.3617 - acc: 0.8263 - val_loss: 1.3643 - val_acc: 0.5952\n",
      "Epoch 12/20\n",
      "6362/6362 [==============================] - 502s - loss: 0.3407 - acc: 0.8392 - val_loss: 1.3870 - val_acc: 0.5958\n",
      "Epoch 13/20\n",
      "6362/6362 [==============================] - 509s - loss: 0.3216 - acc: 0.8515 - val_loss: 1.5938 - val_acc: 0.5890\n",
      "Epoch 14/20\n",
      "6362/6362 [==============================] - 509s - loss: 0.3126 - acc: 0.8516 - val_loss: 1.7833 - val_acc: 0.5804\n",
      "Epoch 15/20\n",
      "6362/6362 [==============================] - 498s - loss: 0.2999 - acc: 0.8566 - val_loss: 1.7263 - val_acc: 0.5918\n",
      "Epoch 16/20\n",
      "6362/6362 [==============================] - 496s - loss: 0.2882 - acc: 0.8588 - val_loss: 1.9691 - val_acc: 0.6100\n",
      "Epoch 17/20\n",
      "6362/6362 [==============================] - 513s - loss: 0.2857 - acc: 0.8618 - val_loss: 2.2048 - val_acc: 0.5884\n",
      "Epoch 18/20\n",
      "6362/6362 [==============================] - 516s - loss: 0.2802 - acc: 0.8655 - val_loss: 2.0724 - val_acc: 0.6009\n",
      "Epoch 19/20\n",
      "6362/6362 [==============================] - 505s - loss: 0.2750 - acc: 0.8666 - val_loss: 1.8164 - val_acc: 0.6020\n",
      "Epoch 20/20\n",
      "6362/6362 [==============================] - 506s - loss: 0.2707 - acc: 0.8743 - val_loss: 2.1886 - val_acc: 0.6083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a670bfa90>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "#          batch_size=128, epochs=2, validation_data=(X_test, y_test))\n",
    "         batch_size=16, epochs=20, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x7f8a67d85278>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.embeddings.Embedding at 0x7f8a67d85240>,\n",
       " <keras.layers.convolutional.Conv1D at 0x7f8a67d852b0>,\n",
       " <keras.layers.pooling.MaxPooling1D at 0x7f8a67d0b198>,\n",
       " <keras.layers.convolutional.Conv1D at 0x7f8a67d0b2e8>,\n",
       " <keras.layers.pooling.MaxPooling1D at 0x7f8a67cf3550>,\n",
       " <keras.layers.core.Flatten at 0x7f8a67cf3470>,\n",
       " <keras.layers.core.Dense at 0x7f8a67c57d68>,\n",
       " <keras.layers.core.Dense at 0x7f8a67c6e6d8>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x7f8a67c57d68>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'activity_regularizer': None,\n",
       " 'bias_constraint': None,\n",
       " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       " 'bias_regularizer': None,\n",
       " 'kernel_constraint': None,\n",
       " 'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "  'config': {'distribution': 'uniform',\n",
       "   'mode': 'fan_avg',\n",
       "   'scale': 1.0,\n",
       "   'seed': None}},\n",
       " 'kernel_regularizer': None,\n",
       " 'name': 'dense_21',\n",
       " 'trainable': True,\n",
       " 'units': 32,\n",
       " 'use_bias': True}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-2].get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2848\n",
      "2786\n",
      "26\n",
      "5660\n"
     ]
    }
   ],
   "source": [
    "print(len([y for y in y_train if y=='d']))\n",
    "print(len([y for y in y_train if y=='r']))\n",
    "print(len([y for y in y_train if y=='i']))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49061967026719727"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.asarray(['d'] * len(y_test))\n",
    "acc = np.mean(preds == y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nb(X_train, X_test, y_train, y_test):\n",
    "    \"\"\" Trains Naive Bayes classifier\n",
    "    Returns (accuracy, classifier)\n",
    "    \"\"\"\n",
    "    \n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    preds = clf.predict(X_test)\n",
    "    acc = np.mean(preds == y_test)\n",
    "    return acc, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, clf = nb(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class d\n",
      "mr yield chairman gentleman speaker time amendment minutes gentlewoman balance committee energy vote california budget people ms new texas oil\n",
      "\n",
      "Class i\n",
      "mr speaker remains minutes jobs yield gentleman trade vote china time wto maryland amplify indiana long wages inquire ohio workers\n",
      "\n",
      "Class r\n",
      "chairman mr yield gentleman time speaker balance amendment minutes reserve committee madam gentlewoman energy new thank vote house ask support\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_features(v, clf, ['d', 'i','r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 15319)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3183.,    26.,  3153.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -7.37282281, -10.43592784, -10.42524935, ..., -10.43592784,\n",
       "        -10.43592784, -10.43592784],\n",
       "       [ -9.55378543,  -9.62492998,  -9.62492998, ...,  -9.62492998,\n",
       "         -9.62492998,  -9.62492998],\n",
       "       [ -7.61797486, -10.37116572, -10.37116572, ..., -10.37116572,\n",
       "        -10.37116572, -10.37116572]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_features(vectorizer, clf, labels, n=20):\n",
    "    \"\"\"Prints features with the highest coefficient values\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    \n",
    "    for i in range(clf.coef_.shape[0]):\n",
    "        print(\"Class {}\".format(labels[i]))\n",
    "        top = np.argsort(clf.coef_[i])[-1*n:]\n",
    "        print(\" \".join(reversed([feature_names[j] for j in top])))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (one-vs-the-rest classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7151790790221717"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "acc = np.mean(preds == y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of ngrams (up to trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6362, 488683)\n",
      "(1759, 488683)\n"
     ]
    }
   ],
   "source": [
    "v = TfidfVectorizer(min_df=1, ngram_range=(1,3))\n",
    "\n",
    "bow_train = train['text'].values\n",
    "bow_test = test['text'].values\n",
    "y_train = train['party'].values\n",
    "y_test = test['party'].values\n",
    "\n",
    "bow = v.fit(bow_train)\n",
    "bow = v.fit(bow_test)\n",
    "\n",
    "X_train = v.transform(bow_train)\n",
    "X_test = v.transform(bow_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65321205230244461"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb(X_train, X_test, y_train, y_test) # too many features--need feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set (and +dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5660"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dirpath = '/home/michael/school/research/convote/convote_v1.1/data_stage_one/training_set/'\n",
    "\n",
    "outlines = []\n",
    "\n",
    "for fname in sorted(os.listdir(data_dirpath)):\n",
    "    party = fname[-7].lower()\n",
    "    \n",
    "    with open(os.path.join(data_dirpath, fname)) as f:\n",
    "        text = f.read()\n",
    "        \n",
    "    id = fname[:-4]\n",
    "    \n",
    "    outlines.append([id, party, text])\n",
    "    \n",
    "len(outlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(outlines, columns=['id', 'party', 'text']).to_csv('/home/michael/school/research/convote/convote_1train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6362"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dirpath = '/home/michael/school/research/convote/convote_v1.1/data_stage_one/development_set/'\n",
    "\n",
    "for fname in sorted(os.listdir(data_dirpath)):\n",
    "    party = fname[-7].lower()\n",
    "    \n",
    "    with open(os.path.join(data_dirpath, fname)) as f:\n",
    "        text = f.read()\n",
    "        \n",
    "    id = fname[:-4]\n",
    "    \n",
    "    outlines.append([id, party, text])\n",
    "    \n",
    "len(outlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(outlines, columns=['id', 'party', 'text']).to_csv('/home/michael/school/research/convote/convote_1train_dev.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1759"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dirpath = '/home/michael/school/research/convote/convote_v1.1/data_stage_one/test_set/'\n",
    "\n",
    "outlines = []\n",
    "\n",
    "for fname in sorted(os.listdir(data_dirpath)):\n",
    "    party = fname[-7].lower()\n",
    "    \n",
    "    with open(os.path.join(data_dirpath, fname)) as f:\n",
    "        text = f.read()\n",
    "        \n",
    "    id = fname[:-4]\n",
    "    \n",
    "    outlines.append([id, party, text])\n",
    "    \n",
    "len(outlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(outlines, columns=['id', 'party', 'text']).to_csv('/home/michael/school/research/convote/convote_1test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
