{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with DocuScope features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6362\n",
      "1759\n"
     ]
    }
   ],
   "source": [
    "# Load train and test\n",
    "train = pd.read_csv('/home/michael/school/research/convote/convote_1train_dev.csv', keep_default_na=False)\n",
    "test = pd.read_csv('/home/michael/school/research/convote/convote_1test.csv', keep_default_na=False)\n",
    "\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out non-stance-related DocuScope features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "173\n",
      "19283\n"
     ]
    }
   ],
   "source": [
    "# Load hierarchy\n",
    "desc_file = '/home/michael/school/research/docuscope/DocuScope 4.06.01 (2017.11.05)/dicts/en/default/_tones.txt'\n",
    "\n",
    "hierarchy = {}\n",
    "\n",
    "with open(desc_file) as f:\n",
    "    cluster = ''\n",
    "    dimension = ''\n",
    "    \n",
    "    # counters\n",
    "    cluster_ctr = 0\n",
    "    dimension_ctr = 0\n",
    "    lat_ctr = 0\n",
    "    \n",
    "    for l in f.read().splitlines():\n",
    "        typ, name = l.split(': ')\n",
    "        \n",
    "        if typ == 'CLUSTER':\n",
    "            cluster = name\n",
    "            if not name in hierarchy:\n",
    "                hierarchy[name] = {}\n",
    "            cluster_ctr += 1\n",
    "            \n",
    "        elif typ == 'DIMENSION':\n",
    "            dimension = name\n",
    "            if not name in hierarchy[cluster]:\n",
    "                hierarchy[cluster][dimension] = []\n",
    "            dimension_ctr += 1\n",
    "            \n",
    "        elif typ == 'LAT':\n",
    "            hierarchy[cluster][dimension].append(name)\n",
    "            lat_ctr += 1\n",
    "            \n",
    "print(cluster_ctr)\n",
    "print(dimension_ctr)\n",
    "print(lat_ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Academic', 'Character', 'Citation', 'ConfidenceHedged', 'ConfidenceHigh', 'ConfidenceLow', 'Contingent', 'Description', 'Facilitate', 'Forceful', 'FirstPerson', 'Future', 'Information', 'Inquiry', 'Interactive', 'Metadiscourse', 'Narrative', 'Negative', 'Positive', 'Public', 'Reasoning', 'Strategic', 'SyntacticComplexity', 'Uncertainty', 'Updates', 'Orphaned'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchy.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Academic', 'Character', 'Citation', 'ConfidenceHedged', 'ConfidenceHigh', 'ConfidenceLow', 'Contingent', 'Description', 'Facilitate', 'Forceful', 'FirstPerson', 'Future', 'Information', 'Inquiry', 'Interactive', 'Metadiscourse', 'Narrative', 'Negative', 'Positive', 'Public', 'Reasoning', 'Strategic', 'SyntacticComplexity', 'Uncertainty', 'Updates', 'Orphaned'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchy.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters_exclude = ['Description', 'Information', 'Narrative', 'SyntacticComplexity', 'Updates', 'Orphaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims_exclude = [hierarchy[c] for c in clusters_exclude]\n",
    "dims_exclude = [x for dims in dims_exclude for x in dims]\n",
    "len(dims_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6605"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lats_exclude = []\n",
    "\n",
    "for c in clusters_exclude:\n",
    "    for d in hierarchy[c]:\n",
    "        lats_exclude.extend(hierarchy[c][d])\n",
    "        \n",
    "len(lats_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just DocuScope features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6362, 5677)\n",
      "(1759, 5677)\n"
     ]
    }
   ],
   "source": [
    "v = TfidfVectorizer(min_df=1, stop_words='english')\n",
    "\n",
    "feats_train = train['lat_str'] + train['dim_str'] + train['cluster_str']\n",
    "feats_test = test['lat_str'] + test['dim_str'] + test['cluster_str']\n",
    "\n",
    "bow_train = feats_train.values\n",
    "bow_test = feats_test.values\n",
    "\n",
    "y_train = train['party'].values\n",
    "y_test = test['party'].values\n",
    "\n",
    "bow = v.fit(bow_train)\n",
    "bow = v.fit(bow_test)\n",
    "\n",
    "X_train = v.transform(bow_train)\n",
    "X_test = v.transform(bow_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb: 0.572484366117112\n",
      "svm: 0.6361569073337123\n"
     ]
    }
   ],
   "source": [
    "for c in ['nb', 'svm']:\n",
    "    acc, _ = classify(X_train, X_test, y_train, y_test, classifier=c)\n",
    "    print('{}: {}'.format(c,acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigrams + DocuScope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6362, 18449)\n",
      "(1759, 18449)\n"
     ]
    }
   ],
   "source": [
    "v = TfidfVectorizer(min_df=1, stop_words='english')\n",
    "\n",
    "# feats_train = train['text'] + train['lat_str'] + train['dim_str'] + train['cluster_str']\n",
    "# feats_test = test['text'] + test['lat_str'] + test['dim_str'] + test['cluster_str']\n",
    "\n",
    "# feats_train = train['text'] + train['lat_restr'] + train['dim_restr'] + train['cluster_restr']\n",
    "# feats_test = test['text'] + test['lat_restr'] + test['dim_restr'] + test['cluster_restr']\n",
    "\n",
    "feats_train = train['text'] + train['lat_restr']\n",
    "feats_test = test['text'] + test['lat_restr']\n",
    "\n",
    "bow_train = feats_train.values\n",
    "bow_test = feats_test.values\n",
    "y_train = train['party'].values\n",
    "y_test = test['party'].values\n",
    "\n",
    "bow = v.fit(bow_train)\n",
    "bow = v.fit(bow_test)\n",
    "\n",
    "X_train = v.transform(bow_train)\n",
    "X_test = v.transform(bow_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\tsvm: 0.7151790790221717\t\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "selectors = {}\n",
    "# for i in [1000, 2000, 5000, 10000, 'all']:\n",
    "for i in [10000]:\n",
    "    selector = SelectKBest(chi2, k=i).fit(X_train, y_train)\n",
    "    X_train_reduced = selector.transform(X_train)\n",
    "    X_test_reduced = selector.transform(X_test)\n",
    "\n",
    "    print(i, end='\\t')\n",
    "    \n",
    "#     for c in ['nb', 'svm']:\n",
    "#     for c in ['nb']:\n",
    "    for c in ['svm']:\n",
    "        acc, clf = classify(X_train_reduced, X_test_reduced, y_train, y_test, classifier=c)\n",
    "        print('{}: {}'.format(c,acc), end='\\t')\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class d\n",
      "busiest hematopoietic engineered imam charcognitivestatesdiverted breath cagnoli misfortune matches colors distrust milhorn frustrations dynes mirage charcognitivestatesdeliberateconsciouswillingly belts helpless hilton broke\n",
      "\n",
      "Class i\n",
      "acadcarsintromove3nichedescriberesearch disasters mammals dred considerable mandates charcognitivestatesawarenesslackawareness eminent kissimmee icsi appropriators misdemeanor apologized indentured forceignite merry gentle liz mere mcdermott\n",
      "\n",
      "Class r\n",
      "laden mistakes 1798 interquestionhowmany distribution drew mete intrusions fooled constraints chartypesobese cosponsoring kind crammed bedridden harness grabbed futureindefinitegeneration inqcuriositystudy 497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_features(v, clf, clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def most_informative_feature_for_class(vectorizer, classifier, classlabel, n=10):\n",
    "    labelid = list(classifier.classes_).index(classlabel)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    topn = sorted(zip(classifier.coef_[labelid], feature_names))[-n:]\n",
    "\n",
    "    for coef, feat in topn:\n",
    "        print(classlabel, feat, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d gorge 1.71833725563\n",
      "d islamists 1.72706757969\n",
      "d delegates 1.72765021448\n",
      "d descriptmotionshandedbeing 1.74106707485\n",
      "d blacks 1.75651952758\n",
      "d boxes 1.78952963044\n",
      "d charcognitivestatesmakesenseof 2.11793251342\n",
      "d healing 2.22013273602\n",
      "d drinking 2.48694784324\n",
      "d booth 3.06154917367\n",
      "i irvine 0.612978561987\n",
      "i charcognitivestatesdeliberateconsciousvoluntarily 0.637849128751\n",
      "i disagree 0.67470144268\n",
      "i eighteenth 0.72428827712\n",
      "i descriptspacerelationisolateremote 0.765414163687\n",
      "i abrogation 0.876000092233\n",
      "i decals 0.876000092233\n",
      "i inspired 0.887199577573\n",
      "i descriptmotionsflow 1.00442246093\n",
      "i earmarked 1.31770830546\n",
      "r chartypesmobster 1.52840648643\n",
      "r faulty 1.53907594127\n",
      "r 172 1.61020523923\n",
      "r disagrees 1.66548417965\n",
      "r detrimental 1.69184158738\n",
      "r intricate 1.7513060369\n",
      "r connecticut 1.75819087165\n",
      "r induced 1.77223195851\n",
      "r jacobs 1.89537628173\n",
      "r inforeportomitleaveout 2.35190006864\n"
     ]
    }
   ],
   "source": [
    "for l in clf.classes_:\n",
    "    most_informative_feature_for_class(v, clf, l, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_features(vectorizer, clf, labels, n=20):\n",
    "    \"\"\"Prints features with the highest coefficient values\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    \n",
    "    for i in range(clf.coef_.shape[0]):\n",
    "        print(\"Class {}\".format(labels[i]))\n",
    "        top = np.argsort(clf.coef_[i])[-1*n:]\n",
    "        print(\" \".join(reversed([feature_names[j] for j in top])))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic classifier (takes Naive Bayes, SVM, eg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(X_train, X_test, y_train, y_test, classifier='nb'):\n",
    "    \"\"\" Trains classifiers\n",
    "    Args:\n",
    "        classifier: {'nb', 'svm'}\n",
    "    \n",
    "    Returns (accuracy, classifier)\n",
    "    \"\"\"\n",
    "    \n",
    "    if classifier == 'nb':\n",
    "        clf = MultinomialNB()\n",
    "        \n",
    "    elif classifier == 'svm':\n",
    "        clf = svm.LinearSVC()\n",
    "        \n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    preds = clf.predict(X_test)\n",
    "    acc = np.mean(preds == y_test)\n",
    "    return acc, clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding in DocuScope features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "\n",
      "5660\n",
      "5660\n",
      "development\n",
      "\n",
      "702\n",
      "702\n",
      "test\n",
      "\n",
      "1759\n",
      "1759\n"
     ]
    }
   ],
   "source": [
    "# Get Docuscope features per document\n",
    "\n",
    "for fold in ['training', 'development', 'test']:\n",
    "    print(fold)\n",
    "    docuscope_dirpath = '/home/michael/school/research/convote/convote_docuscope/_{}_set'.format(fold)\n",
    "    \n",
    "    ds_feats = [] # List of features to make a dataframe, will merge with convote text\n",
    "    \n",
    "    for fname in tqdm(sorted(os.listdir(docuscope_dirpath))):\n",
    "        fpath = os.path.join(docuscope_dirpath, fname)\n",
    "\n",
    "        data = pd.read_table(fpath, names=['token', 'lat', 'dimension', 'cluster'])\n",
    "\n",
    "        lats = [l for l in data['lat'].tolist() if isinstance(l, str)]\n",
    "        dims = [l for l in data['dimension'].tolist() if isinstance(l, str)]\n",
    "        clusters = [l for l in data['cluster'].tolist() if isinstance(l, str)]\n",
    "\n",
    "        lats_ex = [l for l in lats if not l in lats_exclude]\n",
    "        dims_ex = [l for l in dims if not l in dims_exclude]\n",
    "        clusters_ex = [l for l in clusters if not l in clusters_exclude]\n",
    "        \n",
    "        ds_feats.append([fname[:-4], ' '.join(lats), ' '.join(dims), ' '.join(clusters),\n",
    "                        ' '.join(lats_ex), ' '.join(dims_ex), ' '.join(clusters_ex)])\n",
    "\n",
    "    df = pd.read_csv('/home/michael/school/research/convote/convote_1{}_text.csv'.format(fold))\n",
    "\n",
    "    # Merge in LATs as a string\n",
    "    lat_df = pd.DataFrame(ds_feats, columns=['id', 'lat_str', 'dim_str', 'cluster_str', \n",
    "                                             'lat_restr', 'dim_restr', 'cluster_restr'])\n",
    "    merged = pd.merge(df, lat_df)\n",
    "    print(len(df))\n",
    "    print(len(merged))\n",
    "\n",
    "    merged.to_csv('/home/michael/school/research/convote/convote_1{}.csv'.format(fold), index=False)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6362\n",
      "Index(['id', 'party', 'text', 'lat_str', 'dim_str', 'cluster_str', 'lat_restr',\n",
      "       'dim_restr', 'cluster_restr'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Make train+dev\n",
    "\n",
    "train = pd.read_csv('/home/michael/school/research/convote/convote_1training.csv')\n",
    "dev = pd.read_csv('/home/michael/school/research/convote/convote_1development.csv')\n",
    "\n",
    "train_dev = pd.concat([train, dev])\n",
    "print(len(train_dev))\n",
    "print(train_dev.columns)\n",
    "\n",
    "train_dev.to_csv('/home/michael/school/research/convote/convote_1train_dev.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6362\n",
      "1759\n"
     ]
    }
   ],
   "source": [
    "# Load train and test\n",
    "train = pd.read_csv('/home/michael/school/research/convote/convote_1train_dev.csv')\n",
    "test = pd.read_csv('/home/michael/school/research/convote/convote_1test.csv')\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6362, 14702)\n",
      "(1759, 14702)\n"
     ]
    }
   ],
   "source": [
    "# Add in lemmatizer\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
    "\n",
    "v = TfidfVectorizer(min_df=1, stop_words='english', tokenizer=LemmaTokenizer())\n",
    "\n",
    "bow_train = train['text'].values\n",
    "bow_test = test['text'].values\n",
    "y_train = train['party'].values\n",
    "y_test = test['party'].values\n",
    "\n",
    "bow = v.fit(bow_train)\n",
    "bow = v.fit(bow_test)\n",
    "\n",
    "X_train = v.transform(bow_train)\n",
    "X_test = v.transform(bow_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\tnb: 0.6554860716316089\tsvm: 0.6810687890847072\t\n",
      "2000\tnb: 0.671404206935759\tsvm: 0.6861853325753269\t\n",
      "5000\tnb: 0.6895963615690733\tsvm: 0.6986924388857305\t\n",
      "10000\tnb: 0.686753837407618\tsvm: 0.7043774872086412\t\n",
      "all\tnb: 0.6839113132461626\tsvm: 0.7066515065378056\t\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "selectors = {}\n",
    "for i in [1000, 2000, 5000, 10000, 'all']:\n",
    "# for i in [10000]:\n",
    "    selector = SelectKBest(chi2, k=i).fit(X_train, y_train)\n",
    "    X_train_reduced = selector.transform(X_train)\n",
    "    X_test_reduced = selector.transform(X_test)\n",
    "\n",
    "    print(i, end='\\t')\n",
    "    \n",
    "    for c in ['nb', 'svm']:\n",
    "#     for c in ['nb']:\n",
    "#     for c in ['svm']:\n",
    "        acc, clf = classify(X_train_reduced, X_test_reduced, y_train, y_test, classifier=c)\n",
    "        print('{}: {}'.format(c,acc), end='\\t')\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class d\n",
      "mr yield chairman gentleman speaker time amendment minutes gentlewoman balance committee energy vote california budget people ms new texas oil\n",
      "\n",
      "Class i\n",
      "mr speaker remains minutes jobs yield gentleman trade vote china time wto maryland amplify indiana long wages inquire ohio workers\n",
      "\n",
      "Class r\n",
      "chairman mr yield gentleman time speaker balance amendment minutes reserve committee madam gentlewoman energy new thank vote house ask support\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_features(v, clf, ['d', 'i','r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 15319)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3183.,    26.,  3153.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -7.37282281, -10.43592784, -10.42524935, ..., -10.43592784,\n",
       "        -10.43592784, -10.43592784],\n",
       "       [ -9.55378543,  -9.62492998,  -9.62492998, ...,  -9.62492998,\n",
       "         -9.62492998,  -9.62492998],\n",
       "       [ -7.61797486, -10.37116572, -10.37116572, ..., -10.37116572,\n",
       "        -10.37116572, -10.37116572]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_features(vectorizer, clf, labels, n=20):\n",
    "    \"\"\"Prints features with the highest coefficient values\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    \n",
    "    for i in range(clf.coef_.shape[0]):\n",
    "        print(\"Class {}\".format(labels[i]))\n",
    "        top = np.argsort(clf.coef_[i])[-1*n:]\n",
    "        print(\" \".join(reversed([feature_names[j] for j in top])))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2848\n",
      "2786\n",
      "26\n",
      "5660\n"
     ]
    }
   ],
   "source": [
    "print(len([y for y in y_train if y=='d']))\n",
    "print(len([y for y in y_train if y=='r']))\n",
    "print(len([y for y in y_train if y=='i']))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49061967026719727"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.asarray(['d'] * len(y_test))\n",
    "acc = np.mean(preds == y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nb(X_train, X_test, y_train, y_test):\n",
    "    \"\"\" Trains Naive Bayes classifier\n",
    "    Returns (accuracy, classifier)\n",
    "    \"\"\"\n",
    "    \n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    preds = clf.predict(X_test)\n",
    "    acc = np.mean(preds == y_test)\n",
    "    return acc, clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (one-vs-the-rest classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7151790790221717"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "acc = np.mean(preds == y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of ngrams (up to trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6362, 488683)\n",
      "(1759, 488683)\n"
     ]
    }
   ],
   "source": [
    "v = TfidfVectorizer(min_df=1, ngram_range=(1,3))\n",
    "\n",
    "bow_train = train['text'].values\n",
    "bow_test = test['text'].values\n",
    "y_train = train['party'].values\n",
    "y_test = test['party'].values\n",
    "\n",
    "bow = v.fit(bow_train)\n",
    "bow = v.fit(bow_test)\n",
    "\n",
    "X_train = v.transform(bow_train)\n",
    "X_test = v.transform(bow_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65321205230244461"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb(X_train, X_test, y_train, y_test) # too many features--need feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset of unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set (and +dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5660"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dirpath = '/home/michael/school/research/convote/convote_v1.1/data_stage_one/training_set/'\n",
    "\n",
    "outlines = []\n",
    "\n",
    "for fname in sorted(os.listdir(data_dirpath)):\n",
    "    party = fname[-7].lower()\n",
    "    \n",
    "    with open(os.path.join(data_dirpath, fname)) as f:\n",
    "        text = f.read()\n",
    "        \n",
    "    id = fname[:-4]\n",
    "    \n",
    "    outlines.append([id, party, text])\n",
    "    \n",
    "len(outlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(outlines, columns=['id', 'party', 'text']).to_csv('/home/michael/school/research/convote/convote_1training_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6362"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dirpath = '/home/michael/school/research/convote/convote_v1.1/data_stage_one/development_set/'\n",
    "\n",
    "for fname in sorted(os.listdir(data_dirpath)):\n",
    "    party = fname[-7].lower()\n",
    "    \n",
    "    with open(os.path.join(data_dirpath, fname)) as f:\n",
    "        text = f.read()\n",
    "        \n",
    "    id = fname[:-4]\n",
    "    \n",
    "    outlines.append([id, party, text])\n",
    "    \n",
    "len(outlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(outlines, columns=['id', 'party', 'text']).to_csv('/home/michael/school/research/convote/convote_1train_dev_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add dev set separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "702"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dirpath = '/home/michael/school/research/convote/convote_v1.1/data_stage_one/development_set/'\n",
    "\n",
    "outlines = []\n",
    "\n",
    "for fname in sorted(os.listdir(data_dirpath)):\n",
    "    party = fname[-7].lower()\n",
    "    \n",
    "    with open(os.path.join(data_dirpath, fname)) as f:\n",
    "        text = f.read()\n",
    "        \n",
    "    id = fname[:-4]\n",
    "    \n",
    "    outlines.append([id, party, text])\n",
    "    \n",
    "len(outlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(outlines, columns=['id', 'party', 'text']).to_csv('/home/michael/school/research/convote/convote_1development_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1759"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dirpath = '/home/michael/school/research/convote/convote_v1.1/data_stage_one/test_set/'\n",
    "\n",
    "outlines = []\n",
    "\n",
    "for fname in sorted(os.listdir(data_dirpath)):\n",
    "    party = fname[-7].lower()\n",
    "    \n",
    "    with open(os.path.join(data_dirpath, fname)) as f:\n",
    "        text = f.read()\n",
    "        \n",
    "    id = fname[:-4]\n",
    "    \n",
    "    outlines.append([id, party, text])\n",
    "    \n",
    "len(outlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(outlines, columns=['id', 'party', 'text']).to_csv('/home/michael/school/research/convote/convote_1test_text.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
